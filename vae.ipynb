{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 184.797684\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 50.110367\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 43.385326\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 40.755516\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 38.414860\n",
      "====> Epoch: 0 Average loss: 45.6168\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 36.543243\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 35.381119\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 34.826843\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 35.652855\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 34.139732\n",
      "====> Epoch: 1 Average loss: 35.1878\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 33.049603\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 33.747704\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 32.482357\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 31.617561\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 34.439060\n",
      "====> Epoch: 2 Average loss: 33.2467\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 31.629871\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 32.445000\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 31.360943\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 32.206627\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 30.437841\n",
      "====> Epoch: 3 Average loss: 32.3535\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 32.008759\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 32.595932\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 32.593109\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 30.807323\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 32.173496\n",
      "====> Epoch: 4 Average loss: 31.7983\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 30.568995\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 31.396179\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 33.352814\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 32.613220\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 31.811069\n",
      "====> Epoch: 5 Average loss: 31.4320\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 29.829168\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 31.050264\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 30.483698\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 30.915859\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 31.399172\n",
      "====> Epoch: 6 Average loss: 31.1798\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 31.132763\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 31.182655\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 30.587765\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 30.533966\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 32.252136\n",
      "====> Epoch: 7 Average loss: 30.9645\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 30.385462\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 29.594009\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 31.191933\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 30.497482\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 31.375378\n",
      "====> Epoch: 8 Average loss: 30.8226\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 32.582882\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 30.541193\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 30.764339\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 31.395428\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 29.525074\n",
      "====> Epoch: 9 Average loss: 30.6552\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 31.756191\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 31.412785\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 30.791691\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 30.033123\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 31.239595\n",
      "====> Epoch: 10 Average loss: 30.5357\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 29.351814\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 30.094837\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 30.336006\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 29.653524\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 30.384102\n",
      "====> Epoch: 11 Average loss: 30.4095\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 32.274002\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 31.197109\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 30.917557\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 30.088554\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 31.086876\n",
      "====> Epoch: 12 Average loss: 30.3156\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 30.327450\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 30.606159\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 30.688341\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 29.261881\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 30.920494\n",
      "====> Epoch: 13 Average loss: 30.2350\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 30.754166\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 29.939533\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 29.632160\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 28.820648\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 30.090111\n",
      "====> Epoch: 14 Average loss: 30.1421\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 29.480789\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 29.312359\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 29.697174\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 29.994202\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 30.922955\n",
      "====> Epoch: 15 Average loss: 30.0483\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 28.963776\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 30.853880\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 30.011740\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 30.277140\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 29.740990\n",
      "====> Epoch: 16 Average loss: 29.9844\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 28.625504\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 29.010105\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 30.450632\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 28.262001\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 29.921427\n",
      "====> Epoch: 17 Average loss: 29.9465\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 29.433899\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 29.217840\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 29.007717\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 30.500702\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 30.314215\n",
      "====> Epoch: 18 Average loss: 29.8634\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 29.921173\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 29.654404\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 31.315933\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 31.103088\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 30.758492\n",
      "====> Epoch: 19 Average loss: 29.8041\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 29.327290\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 30.376991\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 28.660250\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 28.979929\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 28.276472\n",
      "====> Epoch: 20 Average loss: 29.7546\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 29.019787\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 31.634464\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 29.907162\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 28.885967\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 30.009365\n",
      "====> Epoch: 21 Average loss: 29.6870\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 29.612429\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 29.093197\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 28.799854\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 29.876032\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 30.036762\n",
      "====> Epoch: 22 Average loss: 29.6488\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 29.083839\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 28.703627\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 29.693867\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 30.678560\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 29.320686\n",
      "====> Epoch: 23 Average loss: 29.5936\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 30.121437\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 29.931797\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 29.929369\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 28.347374\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 29.120131\n",
      "====> Epoch: 24 Average loss: 29.5032\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 30.248930\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 28.717136\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 29.200974\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 28.788897\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 29.351110\n",
      "====> Epoch: 25 Average loss: 29.4827\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 29.481010\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 29.191936\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 29.724199\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 29.248928\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 31.132683\n",
      "====> Epoch: 26 Average loss: 29.4531\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 29.848015\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 27.725468\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 28.041702\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 29.700245\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 30.493294\n",
      "====> Epoch: 27 Average loss: 29.4022\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 29.362560\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 28.839684\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 29.569811\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 28.812931\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 29.340670\n",
      "====> Epoch: 28 Average loss: 29.3803\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 29.034622\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 28.701122\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 29.952951\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 29.408367\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 28.761780\n",
      "====> Epoch: 29 Average loss: 29.3229\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 29.522440\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 28.769604\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 29.206194\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 29.490910\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 29.272480\n",
      "====> Epoch: 30 Average loss: 29.2851\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 29.171261\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 29.437290\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 31.235405\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 28.470119\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 28.790859\n",
      "====> Epoch: 31 Average loss: 29.2652\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 29.017075\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 28.900406\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 30.198139\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 30.114782\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 28.362814\n",
      "====> Epoch: 32 Average loss: 29.2183\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 29.223078\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 28.818600\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 30.161255\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 30.193375\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 29.009775\n",
      "====> Epoch: 33 Average loss: 29.2062\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 29.130491\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 29.606112\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 28.883026\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 30.025812\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 29.106533\n",
      "====> Epoch: 34 Average loss: 29.1588\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 28.979336\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 28.498972\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 30.307739\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 29.754066\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 28.573013\n",
      "====> Epoch: 35 Average loss: 29.1309\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 29.767422\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 28.491261\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 28.337601\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 28.324524\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 29.473476\n",
      "====> Epoch: 36 Average loss: 29.0936\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 30.115688\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 29.612667\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 28.242687\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 27.885944\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 30.262321\n",
      "====> Epoch: 37 Average loss: 29.0920\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 27.954094\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 28.825731\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 29.743034\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 27.441362\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 29.500883\n",
      "====> Epoch: 38 Average loss: 29.0593\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 29.120358\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 27.799971\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 30.315910\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 28.759659\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 29.277802\n",
      "====> Epoch: 39 Average loss: 29.0595\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 29.476246\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 29.049387\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 28.757090\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 29.592094\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 28.465132\n",
      "====> Epoch: 40 Average loss: 28.9733\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 28.877514\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 29.835896\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 30.667217\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 29.586216\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 29.106855\n",
      "====> Epoch: 41 Average loss: 28.9857\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 28.243595\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 29.120026\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 28.878124\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 28.248493\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 28.406740\n",
      "====> Epoch: 42 Average loss: 28.9404\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 28.041233\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 29.504141\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 29.347315\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 27.242695\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 30.156704\n",
      "====> Epoch: 43 Average loss: 28.9462\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 28.187569\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 30.049015\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 29.006123\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 28.698616\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 28.822941\n",
      "====> Epoch: 44 Average loss: 28.9111\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 28.463398\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 27.768486\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 28.562840\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 28.693039\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 27.474911\n",
      "====> Epoch: 45 Average loss: 28.8988\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 28.910254\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 28.722525\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 28.021080\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 29.562996\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 29.469938\n",
      "====> Epoch: 46 Average loss: 28.8612\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 29.570549\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 28.957176\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 29.948847\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 29.224796\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 28.768024\n",
      "====> Epoch: 47 Average loss: 28.8239\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 30.436363\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 28.375051\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 28.445301\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 29.611809\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 27.188923\n",
      "====> Epoch: 48 Average loss: 28.8185\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 28.254427\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 29.209023\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 29.871094\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 29.714085\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 27.667992\n",
      "====> Epoch: 49 Average loss: 28.8013\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 28.576809\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 28.740318\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 29.427794\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 29.465769\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 29.128044\n",
      "====> Epoch: 50 Average loss: 28.7736\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 28.627869\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 28.752729\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 28.846363\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 28.763538\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 30.747467\n",
      "====> Epoch: 51 Average loss: 28.7588\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 28.435863\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 28.909893\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 28.093452\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 28.927803\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 29.971657\n",
      "====> Epoch: 52 Average loss: 28.7393\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 28.451796\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 28.946981\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 28.313454\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 31.672272\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 30.041393\n",
      "====> Epoch: 53 Average loss: 28.7175\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 28.852491\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 28.140877\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 29.318420\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 29.162439\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 28.804878\n",
      "====> Epoch: 54 Average loss: 28.7237\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 27.991344\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 28.746498\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 29.496296\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 29.992794\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 27.623793\n",
      "====> Epoch: 55 Average loss: 28.6794\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 29.229652\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 29.066433\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 28.961948\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 29.096825\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 28.858862\n",
      "====> Epoch: 56 Average loss: 28.6626\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 28.967670\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 27.578451\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 27.930586\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 27.808121\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 28.375296\n",
      "====> Epoch: 57 Average loss: 28.6448\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 30.573658\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 27.378983\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 28.795229\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 28.445124\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 29.390976\n",
      "====> Epoch: 58 Average loss: 28.6197\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 28.579094\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 27.383743\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 28.522697\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 27.656677\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 28.430305\n",
      "====> Epoch: 59 Average loss: 28.6025\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 27.865814\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 28.625074\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 29.236824\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 27.237534\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 28.652079\n",
      "====> Epoch: 60 Average loss: 28.5889\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 26.958637\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 28.537407\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 28.954082\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 29.839882\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 27.557320\n",
      "====> Epoch: 61 Average loss: 28.5485\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 28.047493\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 28.569414\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 28.074759\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 28.193645\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 27.662098\n",
      "====> Epoch: 62 Average loss: 28.5529\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 29.253815\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 28.207724\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 28.055626\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 28.592140\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 29.248951\n",
      "====> Epoch: 63 Average loss: 28.5143\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 27.643036\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 27.785522\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 28.269318\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 28.577843\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 28.612431\n",
      "====> Epoch: 64 Average loss: 28.5431\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 29.107479\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 27.949417\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 28.007988\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 28.126640\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 28.497763\n",
      "====> Epoch: 65 Average loss: 28.5231\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 27.822773\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 28.514687\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 27.982752\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 27.577215\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 28.968004\n",
      "====> Epoch: 66 Average loss: 28.5044\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 28.215120\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 28.317619\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 28.469221\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 29.493347\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 30.161627\n",
      "====> Epoch: 67 Average loss: 28.4785\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 27.707378\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 27.828409\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 28.581110\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 29.872145\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 27.433346\n",
      "====> Epoch: 68 Average loss: 28.4797\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 29.756540\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 28.372717\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 29.578320\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 27.642414\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 28.538357\n",
      "====> Epoch: 69 Average loss: 28.4562\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 28.816959\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 28.224602\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 28.401056\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 27.581589\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 28.088367\n",
      "====> Epoch: 70 Average loss: 28.4466\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 28.441261\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 28.147470\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 28.432964\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 28.447273\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 29.125797\n",
      "====> Epoch: 71 Average loss: 28.4251\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 27.832340\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 27.596886\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 28.004051\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 29.248693\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 28.965950\n",
      "====> Epoch: 72 Average loss: 28.4110\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 28.564318\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 28.801739\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 27.995747\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 29.119873\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 27.455681\n",
      "====> Epoch: 73 Average loss: 28.3846\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 27.970387\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 28.318081\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 28.903234\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 27.659771\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 28.716278\n",
      "====> Epoch: 74 Average loss: 28.3851\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 29.560696\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 28.077152\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 28.993046\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 27.711670\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 28.536821\n",
      "====> Epoch: 75 Average loss: 28.3943\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 27.930206\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 28.737297\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 28.423790\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 26.969421\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 29.031296\n",
      "====> Epoch: 76 Average loss: 28.3582\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 28.565981\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 28.596905\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 28.223024\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 28.623875\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 29.244940\n",
      "====> Epoch: 77 Average loss: 28.3302\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 28.705765\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 27.714706\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 28.166552\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 28.345392\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 28.194765\n",
      "====> Epoch: 78 Average loss: 28.3132\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 27.308887\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 27.437237\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 28.012241\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 28.115189\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 27.551107\n",
      "====> Epoch: 79 Average loss: 28.3270\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 27.598337\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 29.079945\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 27.944178\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 29.246279\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 27.082022\n",
      "====> Epoch: 80 Average loss: 28.3043\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 27.658272\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 27.530916\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 27.830261\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 28.209738\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 28.000891\n",
      "====> Epoch: 81 Average loss: 28.3148\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 28.872593\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 26.972647\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 30.333694\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 28.106304\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 29.306658\n",
      "====> Epoch: 82 Average loss: 28.3143\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 27.352367\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 28.413528\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 27.316723\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 28.067953\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 28.384510\n",
      "====> Epoch: 83 Average loss: 28.2885\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 29.358013\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 26.743931\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 29.157169\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 29.637081\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 27.796238\n",
      "====> Epoch: 84 Average loss: 28.3026\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 29.191963\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 28.709198\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 28.802719\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 28.382277\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 27.996712\n",
      "====> Epoch: 85 Average loss: 28.2809\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 27.989019\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 26.803371\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 29.417807\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 29.114546\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 27.435720\n",
      "====> Epoch: 86 Average loss: 28.2919\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 27.426928\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 28.689564\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 28.485884\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 27.590801\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 28.237995\n",
      "====> Epoch: 87 Average loss: 28.2437\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 28.565914\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 27.657442\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 28.097424\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 29.273239\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 28.870075\n",
      "====> Epoch: 88 Average loss: 28.2589\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 27.757500\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 28.249662\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 28.920187\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 29.110573\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 28.208221\n",
      "====> Epoch: 89 Average loss: 28.2495\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 28.704155\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 28.152912\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 28.415289\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 27.584568\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 27.136387\n",
      "====> Epoch: 90 Average loss: 28.2187\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 28.330767\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 27.949360\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 28.377495\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 28.366547\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 27.060354\n",
      "====> Epoch: 91 Average loss: 28.2128\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 28.607624\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 27.269897\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 28.068203\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 27.011847\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 29.361027\n",
      "====> Epoch: 92 Average loss: 28.2335\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 29.228123\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 26.838333\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 28.574560\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 27.961111\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 29.672787\n",
      "====> Epoch: 93 Average loss: 28.1954\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 28.236456\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 27.308487\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 27.898090\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 27.799608\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 27.517654\n",
      "====> Epoch: 94 Average loss: 28.2194\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 28.682137\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 27.275753\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 28.394329\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 27.772678\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 27.189341\n",
      "====> Epoch: 95 Average loss: 28.1987\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 28.542904\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 27.741175\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 29.541042\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 27.543976\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 27.423153\n",
      "====> Epoch: 96 Average loss: 28.2088\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 27.603966\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 28.036989\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 26.543827\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 27.637142\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 29.510170\n",
      "====> Epoch: 97 Average loss: 28.1656\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 28.855627\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 27.201860\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 28.398087\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 28.804409\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 27.077799\n",
      "====> Epoch: 98 Average loss: 28.1598\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 27.381260\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 27.576908\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 28.296057\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 28.305164\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 28.199253\n",
      "====> Epoch: 99 Average loss: 28.1747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./vae_img'):\n",
    "    os.mkdir('./vae_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
    "                loss / len(img)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(dataloader.dataset)))\n",
    "    if epoch % 10 == 0:\n",
    "        save = to_img(recon_batch.cpu().data)\n",
    "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './vae.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mean, log_var):\n",
    "    BCE = torch.nn.functional.binary_cross_entropy(\n",
    "        recon_x.view(-1, 28*28), x.view(-1, 28*28), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return (BCE + KLD) / x.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer_sizes, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.MLP = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.MLP.add_module(name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.ReLU())\n",
    "\n",
    "        # 首先对图像特征进行一些变换处理，然后将其展开成一维向量，然后通过全连接层得到均值和方差\n",
    "        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.MLP(x)\n",
    "\n",
    "        means = self.linear_means(x)\n",
    "        log_vars = self.linear_log_var(x)\n",
    "\n",
    "        return means, log_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer_sizes, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.MLP = nn.Sequential()\n",
    "        input_size = latent_size\n",
    "        \n",
    "        for i, (in_size, out_size) in enumerate(zip([input_size] + layer_sizes[:-1], layer_sizes)):\n",
    "            self.MLP.add_module(\n",
    "                name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            if i + 1 < len(layer_sizes):\n",
    "                self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.ReLU())\n",
    "            else:\n",
    "                self.MLP.add_module(name=\"sigmoid\", module=nn.Sigmoid())\n",
    "\n",
    "    def forward(self, z):\n",
    "        #对输入的z进行全接连操作，最后输出一个重构的x\n",
    "        x = self.MLP(z)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_layer_sizes, latent_size, decoder_layer_sizes):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder = Encoder(encoder_layer_sizes, latent_size)\n",
    "        self.decoder = Decoder(decoder_layer_sizes, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(-1, 28 * 28)\n",
    "        means, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(means, log_var)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, means, log_var, z\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        用于对encoder部分输出的均值方差进行重参数化，采样得到隐式表示部分z\n",
    "        :param mu:\n",
    "        :param log_var:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def inference(self, z):\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
